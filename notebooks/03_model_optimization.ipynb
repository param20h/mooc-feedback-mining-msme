{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f301bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All modules imported successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\param\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from data_preprocessing import load_data\n",
    "from feature_extraction import FeatureExtractor\n",
    "from train_model import prepare_train_test_split\n",
    "from evaluate_model import ModelEvaluator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd0565",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a0a3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 140320 reviews from ../data/processed/cleaned_reviews.csv\n",
      "Loaded 140320 reviews\n",
      "\n",
      "üîç Original dataset size: 140320\n",
      "‚úÖ After removing empty reviews: 135939\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CourseId</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-speed-it</td>\n",
       "      <td>BOring</td>\n",
       "      <td>1</td>\n",
       "      <td>boring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-speed-it</td>\n",
       "      <td>Bravo !</td>\n",
       "      <td>5</td>\n",
       "      <td>bravo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-speed-it</td>\n",
       "      <td>Very goo</td>\n",
       "      <td>5</td>\n",
       "      <td>goo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-speed-it</td>\n",
       "      <td>Great course - I recommend it for all, especia...</td>\n",
       "      <td>5</td>\n",
       "      <td>great course recommend especially business man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-speed-it</td>\n",
       "      <td>One of the most useful course on IT Management!</td>\n",
       "      <td>5</td>\n",
       "      <td>one useful course management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CourseId                                             Review  Label  \\\n",
       "0  2-speed-it                                             BOring      1   \n",
       "1  2-speed-it                                            Bravo !      5   \n",
       "2  2-speed-it                                           Very goo      5   \n",
       "3  2-speed-it  Great course - I recommend it for all, especia...      5   \n",
       "4  2-speed-it    One of the most useful course on IT Management!      5   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0                                             boring  \n",
       "1                                              bravo  \n",
       "2                                                goo  \n",
       "3  great course recommend especially business man...  \n",
       "4                       one useful course management  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned data\n",
    "df = load_data('../data/processed/cleaned_reviews.csv')\n",
    "print(f\"Loaded {len(df)} reviews\")\n",
    "\n",
    "# Remove rows with NaN or empty cleaned_review\n",
    "print(f\"\\nüîç Original dataset size: {len(df)}\")\n",
    "df = df[df['cleaned_review'].notna() & (df['cleaned_review'].str.strip() != '')].reset_index(drop=True)\n",
    "print(f\"‚úÖ After removing empty reviews: {len(df)}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644df4c",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a06d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Converting ratings to sentiment labels...\n",
      "‚úÖ Conversion complete!\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "Positive    124855\n",
      "Neutral       5781\n",
      "Negative      5303\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Vectorizer loaded from ../models/tfidf_vectorizer.pkl\n",
      "\n",
      "Feature matrix shape: (135939, 5000)\n",
      "Labels shape: (135939,)\n",
      "\n",
      "Label distribution:\n",
      "sentiment\n",
      "Positive    124855\n",
      "Neutral       5781\n",
      "Negative      5303\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load saved vectorizer or create new one\n",
    "import joblib\n",
    "\n",
    "# Convert ratings to sentiment if needed\n",
    "if 'sentiment' not in df.columns and 'Label' in df.columns:\n",
    "    print(\"\\nüîÑ Converting ratings to sentiment labels...\")\n",
    "    def rating_to_sentiment(rating):\n",
    "        if rating >= 4:\n",
    "            return 'Positive'\n",
    "        elif rating <= 2:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "    df['sentiment'] = df['Label'].apply(rating_to_sentiment)\n",
    "    print(\"‚úÖ Conversion complete!\")\n",
    "    print(f\"Sentiment distribution:\\n{df['sentiment'].value_counts()}\")\n",
    "\n",
    "# Extract features\n",
    "try:\n",
    "    extractor = FeatureExtractor()\n",
    "    extractor.load_vectorizer('../models/tfidf_vectorizer.pkl')\n",
    "    X = extractor.transform(df['cleaned_review'])\n",
    "except:\n",
    "    print(\"Creating new vectorizer...\")\n",
    "    extractor = FeatureExtractor(method='tfidf', max_features=5000, ngram_range=(1, 2))\n",
    "    X = extractor.fit_transform(df['cleaned_review'])\n",
    "\n",
    "y = df['sentiment']  # Use sentiment labels\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"\\nLabel distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e55f6db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Data Split:\n",
      "   Training samples: 108751\n",
      "   Testing samples: 27188\n",
      "   Features: 5000\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = prepare_train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1c1a6f",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb612ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Performing Grid Search for Logistic Regression...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Grid search\n",
    "print(\"üîç Performing Grid Search for Logistic Regression...\")\n",
    "grid_lr = GridSearchCV(\n",
    "    lr,\n",
    "    param_grid_lr,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n‚úÖ Best parameters: {grid_lr.best_params_}\")\n",
    "print(f\"‚úÖ Best cross-validation score: {grid_lr.best_score_:.4f}\")\n",
    "print(f\"‚úÖ Test accuracy: {grid_lr.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04728d37",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV for faster results\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "print(\"üîç Performing Randomized Search for Random Forest...\")\n",
    "random_rf = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_grid_rf,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n‚úÖ Best parameters: {random_rf.best_params_}\")\n",
    "print(f\"‚úÖ Best cross-validation score: {random_rf.best_score_:.4f}\")\n",
    "print(f\"‚úÖ Test accuracy: {random_rf.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b77fe0",
   "metadata": {},
   "source": [
    "## 5. Try Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2277e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training Gradient Boosting Classifier...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müöÄ Training Gradient Boosting Classifier...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m gb \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(\n\u001b[0;32m      6\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m      7\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m      8\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m      9\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m gb\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ Training accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgb\u001b[38;5;241m.\u001b[39mscore(X_train,\u001b[38;5;250m \u001b[39my_train)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Test accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgb\u001b[38;5;241m.\u001b[39mscore(X_test,\u001b[38;5;250m \u001b[39my_test)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "print(\"üöÄ Training Gradient Boosting Classifier...\")\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n‚úÖ Training accuracy: {gb.score(X_train, y_train):.4f}\")\n",
    "print(f\"‚úÖ Test accuracy: {gb.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e1b0a",
   "metadata": {},
   "source": [
    "## 6. Compare Optimized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "models = {\n",
    "    'Optimized Logistic Regression': grid_lr.best_estimator_,\n",
    "    'Optimized Random Forest': random_rf.best_estimator_,\n",
    "    'Gradient Boosting': gb\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Train Accuracy': train_acc,\n",
    "        'Test Accuracy': test_acc\n",
    "    }\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "print(\"\\nüìä Model Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Plot comparison\n",
    "comparison_df.plot(kind='bar', figsize=(10, 6), rot=0)\n",
    "plt.title('Optimized Models Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.legend(['Train Accuracy', 'Test Accuracy'])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/optimized_models_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c736d8e",
   "metadata": {},
   "source": [
    "## 7. Detailed Evaluation of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model\n",
    "best_model_name = comparison_df['Test Accuracy'].idxmax()\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   Test Accuracy: {comparison_df.loc[best_model_name, 'Test Accuracy']:.4f}\")\n",
    "\n",
    "# Comprehensive evaluation\n",
    "evaluator = ModelEvaluator(\n",
    "    best_model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    class_names=['Negative', 'Neutral', 'Positive']  # Adjust as needed\n",
    ")\n",
    "\n",
    "evaluator.print_metrics()\n",
    "evaluator.print_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "evaluator.plot_confusion_matrix(save_path='../reports/figures/confusion_matrix_best.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ac08e",
   "metadata": {},
   "source": [
    "## 8. Save Optimized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5833b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "import joblib\n",
    "\n",
    "model_path = '../models/optimized_best_model.pkl'\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"‚úÖ Best optimized model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f0503",
   "metadata": {},
   "source": [
    "## 9. Feature Importance (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0934221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance for tree-based models\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_names = extractor.get_feature_names()\n",
    "    importances = best_model.feature_importances_\n",
    "    \n",
    "    # Get top 20 features\n",
    "    indices = np.argsort(importances)[-20:][::-1]\n",
    "    top_features = [(feature_names[i], importances[i]) for i in indices]\n",
    "    \n",
    "    # Create dataframe\n",
    "    importance_df = pd.DataFrame(top_features, columns=['Feature', 'Importance'])\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(data=importance_df, x='Importance', y='Feature', palette='viridis')\n",
    "    plt.title('Top 20 Most Important Features', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Importance', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../reports/figures/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüîù Top 10 Most Important Features:\")\n",
    "    print(importance_df.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Selected model doesn't support feature importance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd51f92",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "**Optimization Results:**\n",
    "- Best optimized model: [Name]\n",
    "- Improvement over baseline: [X%]\n",
    "- Final test accuracy: [Y%]\n",
    "\n",
    "**Key Findings:**\n",
    "- Most important features identified\n",
    "- Optimal hyperparameters found\n",
    "- Model ready for deployment\n",
    "\n",
    "**Next Steps:**\n",
    "1. Experiment with transformer models (BERT)\n",
    "2. Implement aspect-based sentiment analysis\n",
    "3. Build deployment pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
